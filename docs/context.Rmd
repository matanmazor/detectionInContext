---
title             : "Context modulates decisions about presence, but not absence"
shorttitle        : "context effects on decisions about presence and absence"

author: 
  - name          : "Matan Mazor"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "Malet Street, London WC1E 7HX"
    email         : "mtnmzor@gmail.com"
  #   role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
  #     - Conceptualization
  #     - Writing - Original Draft Preparation
  #     - Writing - Review & Editing
  
  - name          : "Clare Press"
    affiliation   : "1,2"
    # role:
    #   - Writing - Review & Editing

affiliation:
  - id            : "1"
    institution   : "Birkbeck, University of London"
  - id            : "2"
    institution   : "Wellcome Centre for Human Neuroimaging, UCL"


abstract: |

  
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["r-references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_word
---

# Introduction

After checking Taylor Swift's Wikipedia page, we are confident that she hasn't announced her retirement from music. If she had, it would have been mentioned on her page. We also checked Russian cellist Natalia Gutman's page and didn't see any mention of a similar announcement, but we are not so sure she hasn't made one since her Wikipedia page only gets updated irregularly. The absence of evidence on Wikipedia is enough to make a solid inference in the case of Swift but not in the case of Gutman because we know that information about Swift spreads more efficiently on the internet.

This paper discusses how we make inferences based on the absence of evidence in visual perception. Such inferences about the negation of a hypothesis ($H$) depend on our belief in the probability that we would observe evidence ($E$) if $H$ were true ($p(E|H)$) [@walton1992nonfallacious; @walton2010arguments; @oaksford2004bayesian]. In other words, we believe that something is not true (for example, that Taylor Swift hasn't announced her retirement from music) when we believe that "if it were true, we would have heard about it by now" [@goldberg2011if]. 

Here we examine how people apply a similar reasoning in the domain of visual perception". Simply not perceiving something doesn't mean that it's not there. We also need to be certain that we would have perceived it if it were present. As a result, the timing of decisions about absence provides valuable insight into people's implicit beliefs about their perception and attention. Rapid decisions about absence reflect a belief that presence would have been detected quickly and easily, while slow decisions reflect a belief that presence would have taken longer to detect [@mazor2021inference; @mazor2022efficient].

To contrast cases in which perception is fast versus slow, we make use of a robust finding in visual cognition: our perception of objects is affected by context. For example, we perceive objects better in their natural surroundings [@rossel2022makes]. In this study, we're not focusing on how well participants can perceive objects, but on how quickly they can infer their absence when they're not there. For example, if people believe that objects are easier to perceive in their natural context, this should affect the timing of their decisions about absence. They should be able to quickly decide that an object is missing in a context that allows for speedy perception. But if they are not aware of these context effects, speedy detection will not translate to speedy inference about absence. 

We tested context effects on decisions about absence in two settings: a near-threshold detection setting, where perception is better in matching, congruent contexts, and a visual search setting where target detection is facilitated in non-matching, or incongruent contexts. In both cases we find that subjects fail to properly adjust the timing of their decisions about absence, revealing no insight into context effects on perception. 


```{r setup, include = FALSE}
library("papaja")
r_refs("r-references.bib")
library('reticulate')
library('tidyverse')
library('broom')
library('cowplot')
library('MESS') # for AUCs
library('lsr') # for effect sizes
library('pwr') # for power calculations
library('brms') # for mixed effects modeling
library('BayesFactor') # for Bayesian t test
library('jsonlite') #parsing data from sort_trial
library('afex') #for anova

```

```{python, include=FALSE, eval=FALSE}
import json
import pandas as pd
import numpy as np
from os import path as path

def to_csv(filename):
    dfs=[]
    with open(filename+'.txt') as json_file:
        for i,line in enumerate(json_file):
            if line[0:14]!='Consent given.':
                dfs.append(pd.read_json(line))


    group_df = pd.concat(dfs)
    group_df.to_csv(filename+'.csv', index=False)
    return(group_df)

# group_df = to_csv(path.join('..','experiments','pilots','letters','data','jatos_results_batch1'))
# group_df[group_df.trial_type=='survey-text'].responses

```



# Exp. 1

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. 

## Participants

The research complies with all relevant ethical regulations, and was approved by the Research Ethics Committee of Birkbeck, University of London (study ID number 1812000). Participants were recruited via Prolific, and gave informed consent prior to their participation. To be eligible to take part in this study, their Prolific approval rate had to be 95% or higher, their reported first language English, and their age between 18 and 60. We collected data until we reached 100 included participants (after applying our pre-registered exclusion criteria). The entire experiment took 11 minutes to complete. Participants were paid £1.38 for their participation, equivalent to an hourly wage of £7.50.

## Procedure

Participants detected the presence or absence of a target letter (S or A, in different blocks) in a patch of dynamic grayscale noise presented at 15 frames per second. In each frame, noise was generated by randomly sampling grayscale values from a target image $I$. Specifically, for each pixel $S_{ij}$, we displayed the grayscale value for the corresponding pixel in the original image $I_{ij}$ with some probability $p$, and the grayscale value of a randomly chosen pixel $I_{i'j'}$ with probability $1-p$. On target-absent trials, $p$ was set to $0$, such that grayscale values of all pixels were randomly shuffled, with replacement. On target-present trials, the probability $p$ slowly increased as the trial progressed, according to the formula $p=\frac{v}{1+e^{-0.05(n-40)))}}$ with $n$ representing the frame number, and $v$ the maximum visibility level (see Fig. \@ref(fig:design)). $v$ was calibrated online to achieve performance levels of around 80%, following a 1-up-3-down procedure, starting at $v=0.35$ and following a multiplicative set size of $0.9$, which moved closer to 1 following each change direction in the calibration process. Responses were delivered using the F and G keyboard keys (counterbalancing response mapping across subjects).

```{r design, echo=FALSE, fig.cap="Experimental design. Top left: target visibility as a function of frame number for in target present (blue) and target absent (red) trials. Bottom left: trial structure in practice trials. Top right: trial structure in the main blocks of the experiment, in S- and A- context trials. Bottom right: overall experiment structure. ", out.width = '75%'}
knitr::include_graphics("figures/design.png")
```

After reading the instructions, participants completed four practice trials. In case their accuracy in these four practice trials fell below 3/4, they were reminded of task instructions and given additional practice trials, until reaching the desired accuracy level. Otherwise, they continued to the main part of the experiment. Here, their task was exactly the same, but the noise patch was embedded in a congruent or incongruent context word. For example, when searching for the letter S, the context word CA_H (cash) is congruent but the context word FL_G (flag) is not (see Fig. \@ref(fig:design), upper right panel). To make sure participants are primed with the correct reading of the context word, an image of its meaning was presented for 500 ms following the fixation cross and prior to the presentation of the noise display. Participants were instructed to ignore the image and surrounding letters, and focus on the central stimuli. 

The main part of the experiment comprised four blocks of 16 trials. For approximately half of the participants, in blocks 1 and 2 the target letter was S and in blocks 3 and 4 it was A. The order of letters was reversed for the other half. All context words were presented twice: once when detecting the letter S and once when detecting the letter A. As a result, all context words were presented both as congruent and as incongruent contexts for the target letter. Overall, there were 32 context words: 16 where the missing letter is an A and 16 where it is an S. All words were 4- or 5-letter nouns with S or A in one of the central positions (i.e., position 2 or 3 in 4-letter words and position 3 in 5-letter words). 

### Randomization

The order and timing of experimental events was determined pseudo-randomly by the Mersenne Twister pseudorandom number generator, initialized in a way that ensures registration time-locking [@mazor2018novel]. 


## Data analysis

### Rejection criteria

Participants were excluded if their accuracy falls below 50%. We also excluded participants for having extremely fast or slow reaction times in one or more of the tasks (below 100 milliseconds or above 5 seconds in more than 25% of the trials). 

Trials with response time below 100 milliseconds or above 5 seconds were excluded from the response-time analysis.


## Results

```{r load_and_format_data, echo=FALSE, cache=TRUE}
E1.raw_df <- read_csv('../experiments/letters/data/jatos_resultfiles_batch1/all_data.csv') %>%
  mutate(subj_id=PROLIFIC_PID,
         correct = as.numeric(correct),
         RT = as.numeric(RT),
         present=as.numeric(present),
         resp = response==presence_key,
         context=ifelse(context_string=='M SK','A',context))

pilot.export.df <- read_csv('../experiments/pilots/letters/data/prolific_export_batch2.csv');

E2.raw_df <- read_csv('../experiments/letters2/data/jatos_resultfiles_batch1/all_data.csv') %>%
  mutate(subj_id=PROLIFIC_PID,
         correct = as.numeric(correct),
         RT = as.numeric(RT),
         present=as.numeric(present),
         resp = response==presence_key,
         context=ifelse(context_string=='M SK','A',context)) #I accidentally coded this as S
```

```{r exclusion, echo=FALSE, cache=TRUE}

E1.to_exclude <- E1.raw_df %>%
  filter(test_part=='test1' | test_part=='test2') %>%
  group_by(subj_id) %>%
  summarise(
    accuracy = mean(correct),
    first_quartile_RT = quantile(RT,0.25),
    third_quartile_RT = quantile(RT,0.75)
  ) %>%
  # filter(accuracy<0.5 | first_quartile_RT<100 | third_quartile_RT>5000)
    filter(accuracy<0.5 | first_quartile_RT<100) %>%
  pull(subj_id)


E1.df <- E1.raw_df %>%
  filter(!(subj_id %in% E1.to_exclude));

E2.to_exclude <- E2.raw_df %>%
  filter(test_part=='test1' | test_part=='test2') %>%
  group_by(subj_id) %>%
  summarise(
    accuracy = mean(correct),
    first_quartile_RT = quantile(RT,0.25),
    third_quartile_RT = quantile(RT,0.75)
  ) %>%
  filter(accuracy<0.5 | first_quartile_RT<100 | third_quartile_RT>5000) %>%
    # filter(accuracy<0.5 | first_quartile_RT<100) %>%
  pull(subj_id)


E2.df <- E2.raw_df %>%
  filter(!(subj_id %in% E2.to_exclude));

```



```{r plot_visibility_per_frame, echo=FALSE, cache=TRUE}


frame_number = seq(100);
time = 1000*frame_number/15;
n=20;
p=0.35;
steepness = 0.1
vis = p/(1+exp(-steepness*(frame_number-n)));

df <- data.frame(frame_number,time,vis) %>%
    mutate(absent = 0,
           present = vis) %>% 
  gather(condition,vis, absent:present) %>%
  mutate(condition= factor(condition,levels=c('present','absent')))

p <- df %>% 
  ggplot(aes(x=time,y=vis, color=condition)) + 
  geom_line(size=2) + 
  theme_classic() + 
  labs(x='time (ms)', y='visibility') +
  scale_color_manual(values=c("#377eb8", "#e41a1c"))+
  theme(legend.position = "none");

ggsave('figures/visibility.png',p,width=4,height=1.5)


```

```{r descriptives, echo=FALSE, cache=TRUE}

E1.overall_descriptives <- E1.df %>%
    filter(test_part=='test1' | test_part=='test2') %>%
    group_by(subj_id) %>%
    summarise(accuracy=mean(correct),
            resp_bias=mean(resp),
            slow_RT = quantile(RT,0.75)>5000,
            RT=median(RT),
            hit_rate = (sum(correct & present)+0.5)/(sum(present)+1),
            fa_rate = (sum(!correct & !present)+0.5)/(sum(!present)+1),
            d = qnorm(hit_rate)-qnorm(fa_rate),
            c = -0.5*(qnorm(hit_rate)+qnorm(fa_rate)));

E2.overall_descriptives <- E2.df %>%
    filter(test_part=='test1' | test_part=='test2') %>%
    group_by(subj_id) %>%
    summarise(accuracy=mean(correct),
            resp_bias=mean(resp),
            slow_RT = quantile(RT,0.75)>5000,
            RT=median(RT),
            hit_rate = (sum(correct & present)+0.5)/(sum(present)+1),
            fa_rate = (sum(!correct & !present)+0.5)/(sum(!present)+1),
            d = qnorm(hit_rate)-qnorm(fa_rate),
            c = -0.5*(qnorm(hit_rate)+qnorm(fa_rate)));
```

`r E1.raw_df%>%pull(subj_id)%>%unique()%>%length()` participants completed the task. Mean accuracy in the main block experiment was `r E1.overall_descriptives%>%pull(accuracy)%>%mean()` (SD=`r E1.overall_descriptives%>%pull(accuracy)%>%sd()`). The mean median response time was `r printnum(E1.overall_descriptives%>%pull(RT)%>%mean()/1000)` seconds (SD=`r printnum(E1.overall_descriptives%>%pull(RT)%>%sd()/1000)`). These slower than expected responses meant that our pre-registered response-time dependent exclusion criteria were unfit to the data: excluding participants with more than 25% of trials slower than 5 seconds meant excluding `r printnum(E1.overall_descriptives$slow_RT%>%mean()*100)` % of participants and biasing our sample. We therefore decided to revise our plan and include those participants whose responses were slower than 5 seconds in more than 25% of the trials, and to include trials longer than 5 seconds in RT-based analysis. 


```{r H1, echo=FALSE, cache=TRUE}

E1.RT_by_resp <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100) %>%
  group_by(subj_id,resp) %>%
  summarise(RT=median(RT))%>%
  spread(resp,RT,sep='')%>%
  mutate(diff=respTRUE-respFALSE)

E2.RT_by_resp <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100) %>%
  group_by(subj_id,resp) %>%
  summarise(RT=median(RT))%>%
  spread(resp,RT,sep='')%>%
  mutate(diff=respTRUE-respFALSE)
```

```{r H2, echo=FALSE, cache=TRUE}

E1.RT_by_context_in_presence <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & resp) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE);

E1.RT_by_context_in_presence_correct_only <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & resp & correct) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE)

E1.RT_by_context_in_presence_incorrect_only <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & resp & !correct) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE)

E1.RT_by_context_in_presence_S_only <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & resp & target=='S') %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE)

E1.RT_by_context_in_presence_A_only <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & resp & target=='A') %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE)

E2.RT_by_context_in_presence <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & resp) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE);

E2.RT_by_context_in_presence_correct_only <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & resp & correct) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE)

E2.RT_by_context_in_presence_incorrect_only <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & resp & !correct) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE)

E2.RT_by_context_in_presence_S_only <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & resp & target=='S') %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE)

E2.RT_by_context_in_presence_A_only <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & resp & target=='A') %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE)

E2.RT_by_context_in_presence_part1_only <- E2.df %>%
  filter(test_part=='test1'  & RT>100 & resp) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE)

E2.RT_by_context_in_presence_part2_only <- E2.df %>%
  filter(test_part=='test2' & RT>100 & resp ) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE)
```

Since decisions about absence are reached only when the subject can be confident that presence would have been detected, they are commonly slower than decisions about presence [@mazor2021stage]. Indeed, response times were significantly shorter in decisions about presence compared to absence (pre-registered Hypothesis 1: `r printnum(E1.RT_by_resp%>%pull(respTRUE)%>%mean()/1000)` vs `r printnum(E1.RT_by_resp%>%pull(respFALSE)%>%mean()/1000)` seconds; `r apa_print(E1.RT_by_resp%>%pull(diff)%>%t.test())$statistic`). 

Turning to context effects on detection, target-present decisions were significantly faster when the target letter appeared in a congruent compared to an incongruent context (pre-registered Hypothesis 2: `r printnum(E1.RT_by_context_in_presence%>%pull(congTRUE)%>%mean()/1000)` vs `r printnum(E1.RT_by_context_in_presence%>%pull(congFALSE)%>%mean()/1000)` seconds; `r apa_print(E1.RT_by_context_in_presence%>%pull(diff)%>%t.test())$statistic`). This was also the case when restricting the analysis to correct responses only (`r printnum(E1.RT_by_context_in_presence_correct_only%>%pull(congTRUE)%>%mean()/1000)` vs `r printnum(E1.RT_by_context_in_presence_correct_only%>%pull(congFALSE)%>%mean()/1000)` seconds; `r apa_print(E1.RT_by_context_in_presence_correct_only%>%pull(diff)%>%t.test())$statistic`). This finding is consistent with previous reports of sensory sharpening effects of context congruency [@rossel2022makes; @heilbron2020word].


```{r H3, echo=FALSE, cache=TRUE}

E1.RT_by_context_in_absence <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & !resp) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE);

E1.RT_by_context_in_absence_correct_only <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & !resp & correct) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE)

E1.RT_by_context_in_absence_incorrect_only <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & !resp & !correct) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE)

E2.RT_by_context_in_absence <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & !resp) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE);

E2.RT_by_context_in_absence_correct_only <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & !resp & correct) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE)

E2.RT_by_context_in_absence_incorrect_only <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & !resp & !correct) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE)

E2.RT_by_context_in_absence_S_only <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & !resp & target=='S') %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE)

E2.RT_by_context_in_absence_A_only <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & !resp & target=='A') %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE)

E2.RT_by_context_in_absence_part1_only <- E2.df %>%
  filter(test_part=='test1'  & RT>100 & !resp ) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE)

E2.RT_by_context_in_absence_part2_only <- E2.df %>%
  filter(test_part=='test2' & RT>100 & !resp ) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(RT=median(RT))%>%
  spread(cong,RT,sep='')%>%
  mutate(diff=congTRUE-congFALSE)
```


```{r H4, echo=FALSE, cache=TRUE}

E1.RT_by_context_and_response <- merge(
  E1.RT_by_context_in_presence,
  E1.RT_by_context_in_absence,
  by= 'subj_id',
  suffixes = c('presence','absence')) %>%
  mutate(interaction = diffpresence-diffabsence);

E1.RT_by_context_and_response_correct_only <- merge(
  E1.RT_by_context_in_presence_correct_only,
  E1.RT_by_context_in_absence_correct_only,
  by= 'subj_id',
  suffixes = c('presence','absence')) %>%
  mutate(interaction = diffpresence-diffabsence);

E2.RT_by_context_and_response <- merge(
  E2.RT_by_context_in_presence,
  E2.RT_by_context_in_absence,
  by= 'subj_id',
  suffixes = c('presence','absence')) %>%
  mutate(interaction = diffpresence-diffabsence);

E2.RT_by_context_and_response_correct_only <- merge(
  E2.RT_by_context_in_presence_correct_only,
  E2.RT_by_context_in_absence_correct_only,
  by= 'subj_id',
  suffixes = c('presence','absence')) %>%
  mutate(interaction = diffpresence-diffabsence);

E2.RT_by_context_and_response_S_only <- merge(
  E2.RT_by_context_in_presence_S_only,
  E2.RT_by_context_in_absence_S_only,
  by= 'subj_id',
  suffixes = c('presence','absence')) %>%
  mutate(interaction = diffpresence-diffabsence);

E2.RT_by_context_and_response_A_only <- merge(
  E2.RT_by_context_in_presence_A_only,
  E2.RT_by_context_in_absence_A_only,
  by= 'subj_id',
  suffixes = c('presence','absence')) %>%
  mutate(interaction = diffpresence-diffabsence);

E2.RT_by_context_and_response_part1_only <- merge(
  E2.RT_by_context_in_presence_part1_only,
  E2.RT_by_context_in_absence_part1_only,
  by= 'subj_id',
  suffixes = c('presence','absence')) %>%
  mutate(interaction = diffpresence-diffabsence);

E2.RT_by_context_and_response_part2_only <- merge(
  E2.RT_by_context_in_presence_part2_only,
  E2.RT_by_context_in_absence_part2_only,
  by= 'subj_id',
  suffixes = c('presence','absence')) %>%
  mutate(interaction = diffpresence-diffabsence);
```

In contrast to decisions about presence, the timing of decisions about absence was similar when the target letter was missing from a congruent or incongruent context (pre-registered Hypothesis 3: `r printnum(E1.RT_by_context_in_absence%>%pull(congTRUE)%>%mean()/1000)` vs `r printnum(E1.RT_by_context_in_absence%>%pull(congFALSE)%>%mean()/1000)` seconds; `r apa_print(E1.RT_by_context_in_absence%>%pull(diff)%>%t.test())$statistic`). Similarly, we found no effect of context on RT in decisions about absence also when restricting our analysis to correct trials only (`r apa_print(E1.RT_by_context_in_absence_correct_only%>%pull(diff)%>%t.test())$statistic`). Furthermore, the effect of context congruency on response time was stronger in decisions about target presence, compared to decisions about target absence (pre-registered Hypothesis 4: `r apa_print(E1.RT_by_context_and_response%>%pull(interaction)%>%t.test())$statistic`), also when restricting the analysis to correct responses only (`r apa_print(E1.RT_by_context_and_response_correct_only%>%pull(interaction)%>%t.test())$statistic`).

```{r Exp1results, echo=FALSE, fig.cap="Reaction time results", out.width = '75%'}
knitr::include_graphics("figures/quantiles_separate.png")
```

```{r SDT, echo=FALSE, cache=TRUE}

E1.descriptives_by_context<- E1.df %>%
  filter(test_part=='test1' | test_part=='test2') %>%
  mutate(cong = target==context,
         resp = response==presence_key)%>%
  group_by(subj_id,cong) %>%
  summarise(accuracy=mean(correct),
            resp_bias=mean(resp),
            RT=median(RT),
            hit_rate = (sum(correct & present)+0.5)/(sum(present)+1),
            fa_rate = (sum(!correct & !present)+0.5)/(sum(!present)+1),
            d = qnorm(hit_rate)-qnorm(fa_rate),
            c = -0.5*(qnorm(hit_rate)+qnorm(fa_rate)))

E2.descriptives_by_context<- E2.df %>%
  filter(test_part=='test1' | test_part=='test2') %>%
  mutate(cong = target==context,
         resp = response==presence_key)%>%
  group_by(subj_id,cong) %>%
  summarise(accuracy=mean(correct),
            resp_bias=mean(resp),
            RT=median(RT),
            hit_rate = (sum(correct & present)+0.5)/(sum(present)+1),
            fa_rate = (sum(!correct & !present)+0.5)/(sum(!present)+1),
            d = qnorm(hit_rate)-qnorm(fa_rate),
            c = -0.5*(qnorm(hit_rate)+qnorm(fa_rate)))
```
Consistent with a sensory sharpening effect, signal detection sensitivity was `r E1.descriptives_by_context %>%filter(cong)%>%pull(d)%>%mean() %>%printnum()` (SD=`r E1.descriptives_by_context %>%filter(cong)%>%pull(d)%>%sd()%>%printnum()`) when the context matched the target letter, and `r E1.descriptives_by_context %>%filter(!cong)%>%pull(d)%>%mean() %>%printnum()` (SD=`r E1.descriptives_by_context %>%filter(!cong)%>%pull(d)%>%sd()%>%printnum()`) when it did not match the target letter. Sensitivity was significantly higher for congruent contexts (pre-registered Hypothesis 5: `r apa_print(E1.descriptives_by_context %>%select(subj_id,cong,d)%>%spread(cong,d,sep='')%>%mutate(diff=congTRUE-congFALSE)%>%pull(diff)%>%t.test)$statistic`) This effect was driven by an increase in hit rate (`r apa_print(E1.descriptives_by_context %>%select(subj_id,cong,hit_rate)%>%spread(cong,hit_rate,sep='')%>%mutate(diff=congTRUE-congFALSE)%>%pull(diff)%>%t.test)$statistic`), without an effect on the false-positive rate (`r apa_print(E1.descriptives_by_context %>%select(subj_id,cong,fa_rate)%>%spread(cong,fa_rate,sep='')%>%mutate(diff=congTRUE-congFALSE)%>%pull(diff)%>%t.test)$statistic`).

The signal detection criterion was overall positive, indicating that participants were conservative in their responses. We found no significant difference in decision criterion between congruent (`r E1.descriptives_by_context %>%filter(cong)%>%pull(c)%>%mean() %>%printnum()`; SD=`r E1.descriptives_by_context %>%filter(cong)%>%pull(c)%>%sd()%>%printnum()`) and incongruent (`r E1.descriptives_by_context %>%filter(!cong)%>%pull(c)%>%mean() %>%printnum()`; SD=`r E1.descriptives_by_context %>%filter(!cong)%>%pull(c)%>%sd()%>%printnum()`) contexts (pre-registered Hypothesis 6: `r apa_print(E1.descriptives_by_context %>%select(subj_id,cong,c)%>%spread(cong,c,sep='')%>%mutate(diff=congTRUE-congFALSE)%>%pull(diff)%>%t.test)$statistic`).

# Exp. 2: immediate appearance

[EXPLAIN MOTIVATION]

## Participants

We collected data until we reached 300 included participants (after applying our pre-registered exclusion criteria). The entire experiment took 11 minutes to complete. Participants were paid £1.38 for their participation, equivalent to an hourly wage of £7.50.

## Procedure

Exp. 2 was identical to Exp. 1, except two changes. Most importantly, instead of emerging gradually, the visibility of the target letter $p$ remained constant throughout target-present trials. And second, calibration of the visibility level $p$ started at at $p=0.2$, and followed a multiplicative set size of $0.9$ which moved closer to 1 following each change direction in the calibration process. The step size was reset to $0.9$ after the second block to allow separate staircasing for each letter.

## results

`r E2.raw_df%>%pull(subj_id)%>%unique()%>%length()` participants completed the task. Mean accuracy in the main experiment was `r E2.overall_descriptives%>%pull(accuracy)%>%mean()%>%printnum()` (SD=`r E2.overall_descriptives%>%pull(accuracy)%>%sd()%>%printnum()`). The mean median response time was `r printnum(E2.overall_descriptives%>%pull(RT)%>%mean()/1000)` seconds (SD=`r printnum(E2.overall_descriptives%>%pull(RT)%>%sd()/1000)`). `r E2.to_exclude%>%length()` participants were excluded based on our pre-registered exclusion criteria.

Overall, in Exp. 2 we successfully replicated the main results of Exp. 1: subjects were faster to detect the presence of a target letter in a congruent context, but this context effect did not extend to decisions about absence. 

Similar to Exp. 1, response times were significantly shorter in decisions about presence compared to absence (pre-registered Hypothesis 1: `r printnum(E2.RT_by_resp%>%pull(respTRUE)%>%mean()/1000)` vs `r printnum(E2.RT_by_resp%>%pull(respFALSE)%>%mean()/1000)` seconds; `r apa_print(E2.RT_by_resp%>%pull(diff)%>%t.test())$statistic`). 

Target-present decisions were again faster when the target letter appeared in a congruent context, consistent with sensory sharpening (pre-registered Hypothesis 2: `r printnum(E2.RT_by_context_in_presence%>%pull(congTRUE)%>%mean()/1000)` vs `r printnum(E2.RT_by_context_in_presence%>%pull(congFALSE)%>%mean()/1000)` seconds; `r apa_print(E2.RT_by_context_in_presence%>%pull(diff)%>%t.test())$statistic`). This was also the case when restricting the analysis to correct responses (`r printnum(E2.RT_by_context_in_presence_correct_only%>%pull(congTRUE)%>%mean()/1000)` vs `r printnum(E2.RT_by_context_in_presence_correct_only%>%pull(congFALSE)%>%mean()/1000)` seconds; `r apa_print(E2.RT_by_context_in_presence_correct_only%>%pull(diff)%>%t.test())$statistic`). 

Replicating Exp. 1, the timing of decisions about absence was unaffected by the context manipulation (pre-registered Hypothesis 3: `r printnum(E2.RT_by_context_in_absence%>%pull(congTRUE)%>%mean()/1000)` vs `r printnum(E2.RT_by_context_in_absence%>%pull(congFALSE)%>%mean()/1000)` seconds; `r apa_print(E2.RT_by_context_in_absence%>%pull(diff)%>%t.test())$statistic`), also when restricting our analysis to correct trials only (`r apa_print(E2.RT_by_context_in_absence_correct_only%>%pull(diff)%>%t.test())$statistic`). Most importantly, the effect of context congruency on response time was stronger in decisions about target presence, compared to decisions about target absence (pre-registered Hypothesis 4: `r apa_print(E2.RT_by_context_and_response%>%pull(interaction)%>%t.test())$statistic`), even when restricting the analysis to correct responses only (`r apa_print(E2.RT_by_context_and_response_correct_only%>%pull(interaction)%>%t.test())$statistic`).

Turning to accuracy and bias measures, sensitivity was significantly higher for congruent contexts (pre-registered Hypothesis 5: `r E2.descriptives_by_context %>%filter(cong)%>%pull(d)%>%mean() %>%printnum()` versus `r E2.descriptives_by_context %>%filter(!cong)%>%pull(d)%>%mean() %>%printnum()`; `r apa_print(E2.descriptives_by_context %>%select(subj_id,cong,d)%>%spread(cong,d,sep='')%>%mutate(diff=congTRUE-congFALSE)%>%pull(diff)%>%t.test)$statistic`).  This effect was driven by an increase in hit rate (`r apa_print(E2.descriptives_by_context %>%select(subj_id,cong,hit_rate)%>%spread(cong,hit_rate,sep='')%>%mutate(diff=congTRUE-congFALSE)%>%pull(diff)%>%t.test)$statistic`), without an effect on the false-positive rate (`r apa_print(E2.descriptives_by_context %>%select(subj_id,cong,fa_rate)%>%spread(cong,fa_rate,sep='')%>%mutate(diff=congTRUE-congFALSE)%>%pull(diff)%>%t.test)$statistic`).

Finally, the signal detection criterion was overall positive, indicating that participants were conservative in their responses, and lower in congruent (`r E2.descriptives_by_context %>%filter(cong)%>%pull(c)%>%mean() %>%printnum()`; SD=`r E2.descriptives_by_context %>%filter(cong)%>%pull(c)%>%sd()%>%printnum()`) than in incongruent (`r E2.descriptives_by_context %>%filter(!cong)%>%pull(c)%>%mean() %>%printnum()`; SD=`r E2.descriptives_by_context %>%filter(!cong)%>%pull(c)%>%sd()%>%printnum()`) contexts (`r apa_print(E2.descriptives_by_context %>%select(subj_id,cong,c)%>%spread(cong,c,sep='')%>%mutate(diff=congTRUE-congFALSE)%>%pull(diff)%>%t.test)$statistic`). This is in contrast to our finding from Exp. 1, where context had no effect on decision criterion.  


```{r quantiles, echo=FALSE, cache=TRUE}


# a function to map the quantiles of target absent search times to
# target present search times.
getQuantiles <- function(pres,abs,probs) {
  present = quantile(pres,probs)
  absent = quantile(abs,probs)
  return(data.frame(probs, present,absent))
}

E1.quantiles <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & correct) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(getQuantiles(
    RT[resp],
    RT[!resp],
    c(0.5,0.75,0.9,0.95)
  )) %>%
  pivot_longer(cols=c('present','absent'), names_to='resp', values_to='RT')

E1.quantile_congruency_effects <- E1.quantiles %>%
  group_by(subj_id, probs,resp) %>%
  summarise(diff = RT[cong]-RT[!cong]) %>%
  pivot_wider(names_from=resp,values_from=diff)

E1.quantile_summary <- E1.quantiles %>% 
  group_by(subj_id) %>%
  mutate(centeredRT = RT-mean(RT))%>%
  group_by(cong,probs, resp) %>%
  summarise(mean_RT=mean(RT),
            se_RT = se(centeredRT)) %>%
  mutate(resp=factor(resp, levels=c('present','absent')),
         cong=factor(cong,levels=c(TRUE,FALSE), 
                     labels=c('cong.','incong.')))

E1.quantile_plot <- E1.quantile_summary %>% 
  ggplot(aes(x=cong, 
             y=mean_RT, 
             color=probs,
             group=probs)) +
  geom_line(size=1.3)+
  geom_errorbar(aes(ymin=mean_RT-se_RT,ymax=mean_RT+se_RT))+
  facet_grid(~resp)+
  labs(x='',
       y='RT')+
  theme_bw() +
  theme(legend.pos='na')

ggsave('figures/E1Quantiles_separate.png',E1.quantile_plot,width=3.5,height=3.5);

E2.quantiles <- E2.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & correct) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(getQuantiles(
    RT[resp],
    RT[!resp],
    c(0.5,0.75,0.9,0.95)
  )) %>%
  pivot_longer(cols=c('present','absent'), names_to='resp', values_to='RT')

E2.quantile_congruency_effects <- E2.quantiles %>%
  group_by(subj_id, probs,resp) %>%
  summarise(diff = RT[cong]-RT[!cong]) %>%
  pivot_wider(names_from=resp,values_from=diff)

E2.quantile_summary <- E2.quantiles %>% 
  group_by(subj_id) %>%
  mutate(centeredRT = RT-mean(RT))%>%
  group_by(cong,probs, resp) %>%
  summarise(mean_RT=mean(RT),
            se_RT = se(centeredRT)) %>%
  mutate(resp=factor(resp, levels=c('present','absent')),
         cong=factor(cong,levels=c(TRUE,FALSE), 
                     labels=c('cong.','incong.')))

E2.quantile_plot <- E2.quantile_summary %>% 
  ggplot(aes(x=cong, 
             y=mean_RT, 
             color=probs,
             group=probs)) +
  geom_line(size=1.3)+
  geom_errorbar(aes(ymin=mean_RT-se_RT,ymax=mean_RT+se_RT))+
  facet_grid(~resp)+
  labs(x='',
       y='RT')+
  theme_bw() +
  theme(legend.pos='na')

ggsave('figures/E2Quantiles_separate.png',E2.quantile_plot,width=3.5,height=3.5);

```

## Exploratory analysis: the tails of the RT distribution

The absence of a congruency effect on target-absent decision times may be rational if a congruent context has a negative effect on the central tendency of reaction time distributions, without affecting the right tail of the distribution. For example, if subjects are willing to tolerate a miss rate of 10%, their target-absent decision times should not be set according to the median reaction time, but according to the 90th quantile [@liesefeld2016search]. We therefore tested Hypotheses 2 again, but this time using the 90% quantile of the target-present RT distribution instead of its median. 

In Exp. 1, target-present responses in the 90% quantile were faster by `r E1.quantile_congruency_effects %>%filter(probs==0.90)%>%pull(present)%>%mean()%>%abs()%>%round()` ms. in the congruent condition, but this effect was not significant (`r E1.quantile_congruency_effects %>%filter(probs==0.90)%>%pull(present)%>%t.test()%>%apa_print()%>%'$'(statistic)`). 
In Exp. 2, a difference of `r E2.quantile_congruency_effects %>%filter(probs==0.90)%>%pull(present)%>%mean()%>%abs()%>%round()` ms. in the same contrast reached significance (`r E2.quantile_congruency_effects %>%filter(probs==0.90)%>%pull(present)%>%t.test()%>%apa_print()%>%'$'(full_result)`). Similarly, a congruency effect of `r E2.quantile_congruency_effects %>%filter(probs==0.95)%>%pull(present)%>%mean()%>%abs()%>%round()` ms. was observed for 95% quantile target-present response times (`r E2.quantile_congruency_effects %>%filter(probs==0.95)%>%pull(present)%>%t.test()%>%apa_print()%>%'$'(full_result)`).

## Exp. 3: visual search


```{r quantiles2, echo=FALSE, cache=TRUE}


# a function to map the quantiles of target absent search times to
# target present search times.
mapQuantiles <- function(x,y,probs) {
  x_quantiles = quantile(x,probs)
  percentile <- ecdf(y);
  return(percentile(x_quantiles))
}

E1.quantiles <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & correct) %>%
  mutate(cong = target==context)%>%
  group_by(subj_id,cong) %>%
  summarise(enframe(mapQuantiles(
    RT[!resp],
    RT[resp],
    seq(0,1,0.1)
  ), "quantile_absent", "quantile_present"),
  quantile_absent = seq(0,1,0.1)) 

E1.quantile_summary <- E1.quantiles %>% 
  group_by(subj_id,cong) %>%
  summarise(quantile_present=mean(quantile_present)) %>%
  group_by(subj_id) %>%
  summarise(diff=mean(quantile_present[cong])-
              mean(quantile_present[!cong])) 

E1.quantile_plot <- E1.quantiles %>% 
  group_by(cong,quantile_absent) %>% 
  summarise(mean_quantile_present=mean(quantile_present),
            se_quantile_present = se(quantile_present)) %>% 
  ggplot(aes(x=quantile_absent, 
             y=mean_quantile_present, 
             color=cong)) +
  geom_line(size=1)+
  geom_ribbon(aes(x=quantile_absent, 
                  ymin=mean_quantile_present-se_quantile_present,
                  ymax=mean_quantile_present+se_quantile_present, fill=cong),
              alpha=0.5)+
  scale_x_continuous(limits=c(0,1), breaks = seq(0,1,0.1))+
  scale_y_continuous(limits=c(0,1), breaks = seq(0,1,0.1))+
  labs(x='target-absent responses',
       y='target-present responses',
       title='Detection quantiles')+
  theme_bw() +
  scale_fill_manual(values = c("black","#377eb8"))+
  scale_color_manual(values = c("black","#377eb8"))+
  coord_fixed()

ggsave('figures/E1Quantiles.png',E1.quantile_plot,width=5,height=5);

```

```{r Figure, echo=FALSE, cache=TRUE}

N_perm <- 1000;
bootstrap_error <- function(x, N_perm) {
  N <- length(x)
  medians = c();
  for (i in 1:N_perm) {
    medians = c(medians,sample(x,replace=TRUE,size=N)%>%median())
  };
  return(sd(medians))
}

E1.RT_per_cell <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100) %>%
  mutate(cong=target==context)%>%
  group_by(subj_id,resp,cong) %>%
  summarise(RT=median(RT))

E1.RT_per_cell_correct_only <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & correct) %>%
  mutate(cong=target==context)%>%
  group_by(subj_id,resp,cong) %>%
  summarise(RT=median(RT))

E1.RT_per_cell_incorrect_only <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & !correct) %>%
  mutate(cong=target==context)%>%
  group_by(subj_id,resp,cong) %>%
  summarise(RT=median(RT))


p <- E1.RT_per_cell %>% 
  mutate(resp=ifelse(resp, 'present','absent'),
         cong=ifelse(cong,'congruent','incongruent'),
         resp=factor(resp,levels=c('present','absent'))) %>%
  ggplot(aes(x=cong,fill=resp,y=RT, color=resp)) +
  geom_boxplot(size=1,fill='white',outlier.alpha=0) +
  geom_point(position=position_jitterdodge(),alpha=0.3,size=3, show.legend=FALSE)+
  theme_classic() + 
  labs(x='context', y='median RT (ms)',fill='response')+
  scale_color_manual(values=c("#377eb8", "#e41a1c")) +
  scale_fill_manual(values=c("#377eb8", "#e41a1c"))

ggsave('figures/E1_RT_by_cong_resp.png',p,width=5,height=4.5)


p <- E1.RT_per_cell_correct_only %>% 
  mutate(resp=ifelse(resp, 'present','absent'),
         cong=ifelse(cong,'congruent','incongruent'),
         resp=factor(resp,levels=c('present','absent'))) %>%
  ggplot(aes(x=cong,fill=resp,y=RT, color=resp)) +
  geom_boxplot(size=1,fill='white',outlier.alpha=0) +
  geom_point(position=position_jitterdodge(),alpha=0.3,size=3, show.legend=FALSE)+
  theme_classic() + 
  labs(x='context', y='median RT (ms)',fill='response')+
  scale_color_manual(values=c("#377eb8", "#e41a1c")) +
  scale_fill_manual(values=c("#377eb8", "#e41a1c"))


ggsave('figures/E1_RT_by_cong_resp_correct_only.png',p,width=5,height=4.5)

p <- E1.RT_per_cell_incorrect_only %>% 
  mutate(resp=ifelse(resp, 'present','absent'),
         cong=ifelse(cong,'congruent','incongruent'),
         resp=factor(resp,levels=c('present','absent'))) %>%
  ggplot(aes(x=cong,fill=resp,y=RT, color=resp)) +
  geom_boxplot(size=1,fill='white',outlier.alpha=0) +
  geom_point(position=position_jitterdodge(),alpha=0.3,size=3, show.legend=FALSE)+
  theme_classic() + 
  labs(x='context', y='median RT (ms)',fill='response')+
  scale_color_manual(values=c("#377eb8", "#e41a1c")) +
  scale_fill_manual(values=c("#377eb8", "#e41a1c"))


ggsave('figures/E1_RT_by_cong_resp_incorrect_only.png',p,width=5,height=4.5)


```

```{r Figure-first-blocks-only, echo=FALSE, cache=TRUE}



E1.RT_per_cell_by_test_part <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100) %>%
  mutate(cong=target==context)%>%
  group_by(subj_id,resp,cong,test_part) %>%
  summarise(RT=median(RT))

E1.RT_per_cell_correct_only_by_test_part <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & correct) %>%
  mutate(cong=target==context)%>%
  group_by(subj_id,resp,cong, test_part) %>%
  summarise(RT=median(RT))


p <- E1.RT_per_cell_by_test_part %>% 
  mutate(resp=ifelse(resp, 'present','absent'),
         cong=ifelse(cong,'congruent','incongruent'),
         resp=factor(resp,levels=c('present','absent'))) %>%
  ggplot(aes(x=cong,fill=resp,y=RT, color=resp)) +
  geom_boxplot(size=1,fill='white',outlier.alpha=0) +
  geom_point(position=position_jitterdodge(),alpha=0.3,size=3, show.legend=FALSE)+
  theme_classic() + 
  labs(x='context', y='median RT (ms)',fill='response')+
  scale_color_manual(values=c("#377eb8", "#e41a1c")) +
  scale_fill_manual(values=c("#377eb8", "#e41a1c")) + 
  facet_wrap(~test_part)

ggsave('figures/E1_RT_by_cong_resp_by_test_part.png',p,width=7,height=4)


p <- E1.RT_per_cell_correct_only_by_test_part %>% 
  mutate(resp=ifelse(resp, 'present','absent'),
         cong=ifelse(cong,'congruent','incongruent'),
         resp=factor(resp,levels=c('present','absent'))) %>%
  ggplot(aes(x=cong,fill=resp,y=RT, color=resp)) +
  geom_boxplot(size=1,fill='white',outlier.alpha=0) +
  geom_point(position=position_jitterdodge(),alpha=0.3,size=3, show.legend=FALSE)+
  theme_classic() + 
  labs(x='context', y='median RT (ms)',fill='response')+
  scale_color_manual(values=c("#377eb8", "#e41a1c")) +
  scale_fill_manual(values=c("#377eb8", "#e41a1c"))+ 
  facet_wrap(~test_part)


ggsave('figures/E1_RT_by_cong_resp_correct_only_by_test_part.png',p,width=5,height=4.5)


```

```{r Figure-by_target_letter, echo=FALSE, cache=TRUE}



E1.RT_per_cell_by_target <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100) %>%
  mutate(cong=target==context)%>%
  group_by(subj_id,resp,cong,target) %>%
  summarise(RT=median(RT))

E1.RT_per_cell_correct_only_by_target <- E1.df %>%
  filter((test_part=='test1' | test_part=='test2') & RT>100 & correct) %>%
  mutate(cong=target==context)%>%
  group_by(subj_id,resp,cong, target) %>%
  summarise(RT=median(RT))


p <- E1.RT_per_cell_by_target %>% 
  mutate(resp=ifelse(resp, 'present','absent'),
         cong=ifelse(cong,'congruent','incongruent'),
         resp=factor(resp,levels=c('present','absent'))) %>%
  ggplot(aes(x=cong,fill=resp,y=RT, color=resp)) +
  geom_boxplot(size=1,fill='white',outlier.alpha=0) +
  geom_point(position=position_jitterdodge(),alpha=0.3,size=3, show.legend=FALSE)+
  theme_classic() + 
  labs(x='context', y='median RT (ms)',fill='response')+
  scale_color_manual(values=c("#377eb8", "#e41a1c")) +
  scale_fill_manual(values=c("#377eb8", "#e41a1c")) + 
  facet_wrap(~target)

ggsave('figures/E1_RT_by_cong_resp_by_target.png',p,width=7,height=4)


p <- E1.RT_per_cell_correct_only_by_target %>% 
  mutate(resp=ifelse(resp, 'present','absent'),
         cong=ifelse(cong,'congruent','incongruent'),
         resp=factor(resp,levels=c('present','absent'))) %>%
  ggplot(aes(x=cong,fill=resp,y=RT, color=resp)) +
  geom_boxplot(size=1,fill='white',outlier.alpha=0) +
  geom_point(position=position_jitterdodge(),alpha=0.3,size=3, show.legend=FALSE)+
  theme_classic() + 
  labs(x='context', y='median RT (ms)',fill='response')+
  scale_color_manual(values=c("#377eb8", "#e41a1c")) +
  scale_fill_manual(values=c("#377eb8", "#e41a1c"))+ 
  facet_wrap(~target)


ggsave('figures/E1_RT_by_cong_resp_correct_only_by_target.png',p,width=5,height=4.5)


```

```{r format_for_clare, eval=FALSE, echo=FALSE}
E1.RT_per_cell_by_test_part %>%
  mutate(resp=ifelse(resp,'present','absent'), cong=ifelse(cong,'cong','incong')) %>%
  pivot_wider(names_from=c('resp','cong','test_part'),values_from='RT',names_sep='_') %>%
  write.csv('../experiments/letters/data/jatos_resultfiles_batch1/summary_for_Clare.csv')
```


```{r format_for_nondirectional_analysis, eval=FALSE, echo=FALSE}
E1.df %>%   
  filter((test_part=='test1' | test_part=='test2') & RT>100 & correct & resp) %>%
  mutate(cong=ifelse(target==context,1,0),
         subNum = subj_id,
         rt=RT,
         Exp='e1') %>%
  select(subNum,rt,cong, Exp) %>%
  write.csv('../../nondirectionalPriming/data/Mazor_inPrep.csv')
```

```{r format_for_HDDM, eval=FALSE, echo=FALSE}
E1.df %>%   
  filter((test_part=='test1' | test_part=='test2') & RT>100) %>%
  mutate(cong=ifelse(target==context,1,0),
         subj_idx = as.numeric(factor(subj_id)),
         rt=RT/1000,
         stim=ifelse(present,1,0),
         response=ifelse(resp,1,0)) %>%
  select(subj_idx,stim,cong,rt,response) %>%
  write.csv('../experiments/letters/data/jatos_resultfiles_batch1/forHDDM.csv')

E1.df %>%   
  filter((test_part=='test1' | test_part=='test2') & RT>100) %>%
  mutate(cong=ifelse(target==context,1,0),
         subj_idx = as.numeric(factor(subj_id)),
         present = ifelse(present,1,0),
         rt=RT/1000,
         response=ifelse(correct,1,0)) %>%
  select(subj_idx,cong,rt,present,response) %>%
  write.csv('../experiments/letters/data/jatos_resultfiles_batch1/accuracyCodedForHDDM.csv')

```

```{r quartiles, echo=FALSE, cache=TRUE}

E1.accuracy_by_quartile <- E1.df %>%
  filter(test_part=='test1' | test_part=='test2') %>%
  mutate(cong = target==context,
         resp = response==presence_key)%>%
  group_by(subj_id,cong,present) %>%
  mutate(RTq = ntile(RT,4)) %>%
  select(subj_id, cong, present, RTq, RT, correct) %>%
  group_by(subj_id,present,RTq, cong) %>%
  summarise(acc=mean(correct))

p<- E1.accuracy_by_quartile  %>%
  group_by(present,RTq, cong) %>%
  summarise(acc=mean(acc))%>%
  spread(cong,acc,sep='_') %>%
  mutate(cong_effect = cong_TRUE-cong_FALSE) %>% ggplot(
  aes(x=RTq,y=cong_effect,fill=factor(present))
) + geom_bar(stat='identity', position='dodge') +
  labs(x='quartile',y='congruency effect (cong-incong)',fill='stimulus present')

ggsave('figures/E1_RT_by_cong_resp_quartile.png',p,width=5,height=4.5)


```


# Discussion


\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
